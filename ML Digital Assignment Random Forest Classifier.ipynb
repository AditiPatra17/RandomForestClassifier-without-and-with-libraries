{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a20d99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8095238095238095\n",
      "Precision: 0.8\n",
      "Recall: 0.8888888888888888\n",
      "F1-score: 0.8421052631578948\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           M       0.80      0.89      0.84        36\n",
      "           R       0.83      0.70      0.76        27\n",
      "\n",
      "    accuracy                           0.81        63\n",
      "   macro avg       0.81      0.80      0.80        63\n",
      "weighted avg       0.81      0.81      0.81        63\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "sonar = pd.read_csv('sonar.all-data.csv')\n",
    "\n",
    "# Define features and target variable\n",
    "X = sonar.drop(['R'], axis=1)  # Exclude the last column which is the target variable 'R'\n",
    "y = sonar['R']\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # Set random state for reproducibility\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='M')\n",
    "recall = recall_score(y_test, y_pred, pos_label='M')\n",
    "f1 = f1_score(y_test, y_pred, pos_label='M')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Get precision, recall, and F1-score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt='g')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475ed81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
      "0  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "1  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "2  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "3  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "4  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
      "\n",
      "   0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  \\\n",
      "0  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
      "1  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
      "2  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
      "3  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
      "4  0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
      "\n",
      "   0.0090  0.0032  R  \n",
      "0  0.0052  0.0044  R  \n",
      "1  0.0095  0.0078  R  \n",
      "2  0.0040  0.0117  R  \n",
      "3  0.0107  0.0094  R  \n",
      "4  0.0051  0.0062  R  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the loaded dataset\n",
    "print(sonar.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5886eeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.746031746031746\n",
      "Classification Report:\n",
      " Precision: 0.7419354838709677\n",
      "Recall: 0.7419354838709677\n",
      "F1-score: 0.7419354838709677\n",
      "Confusion Matrix:\n",
      "[24, 8]\n",
      "[8, 23]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "with open('sonar.all-data.csv', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "data = [line.strip().split(\",\") for line in lines]\n",
    "headers = data[0]\n",
    "sonar_data = data[1:]\n",
    "\n",
    "# Define features and target variable\n",
    "X = [row[:-1] for row in sonar_data]  # Features\n",
    "y = [row[-1] for row in sonar_data]   # Target variable\n",
    "\n",
    "# Convert target variable to binary labels\n",
    "y = [1 if label == 'M' else 0 for label in y]\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "def train_test_split(X, y, test_size=0.3, random_state=None):\n",
    "    if random_state:\n",
    "        import random\n",
    "        random.seed(random_state)\n",
    "    \n",
    "    data = list(zip(X, y))\n",
    "    random.shuffle(data)\n",
    "    split_index = int(len(data) * (1 - test_size))\n",
    "    X_train, y_train = zip(*data[:split_index])\n",
    "    X_test, y_test = zip(*data[split_index:])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define RandomForestClassifier\n",
    "class RandomForestClassifier:\n",
    "    def __init__(self, n_estimators=100):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionTreeClassifier()\n",
    "            tree.fit(X, y)\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for tree in self.trees:\n",
    "            predictions.append(tree.predict(X))\n",
    "        # Majority voting for binary classification\n",
    "        return [1 if sum(pred) > len(pred) / 2 else 0 for pred in zip(*predictions)]\n",
    "\n",
    "# Decision Tree Classifier\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=3):\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.num_classes = len(set(y))\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "    \n",
    "    def _gini(self, y):\n",
    "        classes = list(set(y))\n",
    "        num_instances = len(y)\n",
    "        gini = 1\n",
    "        for c in classes:\n",
    "            proportion = y.count(c) / num_instances\n",
    "            gini -= proportion ** 2\n",
    "        return gini\n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "        best_gini = float('inf')\n",
    "        best_feature, best_threshold = None, None\n",
    "        for feature_index in range(len(X[0])):\n",
    "            thresholds = set([row[feature_index] for row in X])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = [i for i in range(len(X)) if X[i][feature_index] <= threshold]\n",
    "                right_indices = [i for i in range(len(X)) if X[i][feature_index] > threshold]\n",
    "                left_gini = self._gini([y[i] for i in left_indices])\n",
    "                right_gini = self._gini([y[i] for i in right_indices])\n",
    "                gini = (len(left_indices) * left_gini + len(right_indices) * right_gini) / len(X)\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "        return best_feature, best_threshold\n",
    "    \n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [y.count(i) for i in range(self.num_classes)]\n",
    "        predicted_class = num_samples_per_class.index(max(num_samples_per_class))\n",
    "        node = Node(value=predicted_class)\n",
    "        \n",
    "        if depth < self.max_depth:\n",
    "            feature, threshold = self._best_split(X, y)\n",
    "            if feature is not None:\n",
    "                left_indices = [i for i in range(len(X)) if X[i][feature] <= threshold]\n",
    "                right_indices = [i for i in range(len(X)) if X[i][feature] > threshold]\n",
    "                left_X = [X[i] for i in left_indices]\n",
    "                left_y = [y[i] for i in left_indices]\n",
    "                right_X = [X[i] for i in right_indices]\n",
    "                right_y = [y[i] for i in right_indices]\n",
    "                node = Node(feature, threshold, self._grow_tree(left_X, left_y, depth + 1), self._grow_tree(right_X, right_y, depth + 1))\n",
    "        return node\n",
    "    \n",
    "    def _predict_sample(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict_sample(x, node.left)\n",
    "        else:\n",
    "            return self._predict_sample(x, node.right)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return [self._predict_sample(x, self.tree) for x in X]\n",
    "\n",
    "# Train the model\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    correct = sum(1 for true, pred in zip(y_true, y_pred) if true == pred)\n",
    "    return correct / len(y_true)\n",
    "\n",
    "def precision_score(y_true, y_pred, pos_label):\n",
    "    true_positives = sum(1 for true, pred in zip(y_true, y_pred) if true == pos_label and pred == pos_label)\n",
    "    all_positives = sum(1 for pred in y_pred if pred == pos_label)\n",
    "    if all_positives == 0:\n",
    "        return 0\n",
    "    return true_positives / all_positives\n",
    "\n",
    "def recall_score(y_true, y_pred, pos_label):\n",
    "    true_positives = sum(1 for true, pred in zip(y_true, y_pred) if true == pos_label and pred == pos_label)\n",
    "    relevant = sum(1 for true in y_true if true == pos_label)\n",
    "    if relevant == 0:\n",
    "        return 0\n",
    "    return true_positives / relevant\n",
    "\n",
    "def f1_score(y_true, y_pred, pos_label):\n",
    "    precision = precision_score(y_true, y_pred, pos_label)\n",
    "    recall = recall_score(y_true, y_pred, pos_label)\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Get precision, recall, and F1-score\n",
    "def classification_report(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, pos_label=1)\n",
    "    recall = recall_score(y_true, y_pred, pos_label=1)\n",
    "    f1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "    return f\"Precision: {precision}\\nRecall: {recall}\\nF1-score: {f1}\"\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Confusion Matrix\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    tp = sum(1 for true, pred in zip(y_true, y_pred) if true == pred == 1)\n",
    "    tn = sum(1 for true, pred in zip(y_true, y_pred) if true == pred == 0)\n",
    "    fp = sum(1 for true, pred in zip(y_true, y_pred) if true == 0 and pred == 1)\n",
    "    fn = sum(1 for true, pred in zip(y_true, y_pred) if true == 1 and pred == 0)\n",
    "    return [[tn, fp], [fn, tp]]\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "for row in conf_matrix:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6977d880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5555555555555556\n",
      "Precision: 1.0\n",
      "Recall: 0.0967741935483871\n",
      "F1-score: 0.17647058823529413\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class RandomForestClassifier:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, max_features=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = len(X), len(X[0])\n",
    "        if not self.max_features:\n",
    "            self.max_features = int(n_features ** 0.5)\n",
    "        for _ in range(self.n_estimators):\n",
    "            indices = random.sample(range(n_samples), n_samples)\n",
    "            bootstrap_X = [X[i] for i in indices]\n",
    "            bootstrap_y = [y[i] for i in indices]\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_depth, max_features=self.max_features)\n",
    "            tree.fit(bootstrap_X, bootstrap_y)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for tree in self.trees:\n",
    "            predictions.append(tree.predict(X))\n",
    "        return self._majority_vote(predictions)\n",
    "\n",
    "    def _majority_vote(self, predictions):\n",
    "        return [1 if sum(pred) > len(pred) / 2 else 0 for pred in zip(*predictions)]\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None, max_features=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = len(X), len(X[0])\n",
    "        self.feature_indices = random.sample(range(n_features), self.max_features)\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def _gini(self, y):\n",
    "        classes = list(set(y))\n",
    "        num_instances = len(y)\n",
    "        gini = 1\n",
    "        for c in classes:\n",
    "            proportion = y.count(c) / num_instances\n",
    "            gini -= proportion ** 2\n",
    "        return gini\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        best_gini = float('inf')\n",
    "        best_feature, best_threshold = None, None\n",
    "        for feature_index in self.feature_indices:\n",
    "            thresholds = set([row[feature_index] for row in X])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = [i for i in range(len(X)) if X[i][feature_index] <= threshold]\n",
    "                right_indices = [i for i in range(len(X)) if X[i][feature_index] > threshold]\n",
    "                left_gini = self._gini([y[i] for i in left_indices])\n",
    "                right_gini = self._gini([y[i] for i in right_indices])\n",
    "                gini = (len(left_indices) * left_gini + len(right_indices) * right_gini) / len(X)\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [y.count(i) for i in set(y)]\n",
    "        predicted_class = num_samples_per_class.index(max(num_samples_per_class))\n",
    "        node = Node(value=predicted_class)\n",
    "\n",
    "        if depth < self.max_depth and len(set(y)) > 1:  # Added condition to handle empty classes\n",
    "            feature, threshold = self._best_split(X, y)\n",
    "            if feature is not None:\n",
    "                left_indices = [i for i in range(len(X)) if X[i][feature] <= threshold]\n",
    "                right_indices = [i for i in range(len(X)) if X[i][feature] > threshold]\n",
    "                left_X = [X[i] for i in left_indices]\n",
    "                left_y = [y[i] for i in left_indices]\n",
    "                right_X = [X[i] for i in right_indices]\n",
    "                right_y = [y[i] for i in right_indices]\n",
    "                node = Node(feature, threshold, self._grow_tree(left_X, left_y, depth + 1),\n",
    "                            self._grow_tree(right_X, right_y, depth + 1))\n",
    "        return node\n",
    "\n",
    "\n",
    "    def _predict_sample(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict_sample(x, node.left)\n",
    "        else:\n",
    "            return self._predict_sample(x, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict_sample(x, self.tree) for x in X]\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "# Load the dataset\n",
    "with open('sonar.all-data.csv', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "data = [line.strip().split(\",\") for line in lines]\n",
    "headers = data[0]\n",
    "sonar_data = data[1:]\n",
    "\n",
    "# Define features and target variable\n",
    "X = [list(map(float, row[:-1])) for row in sonar_data]  # Features\n",
    "y = [1 if label == 'M' else 0 for label in [row[-1] for row in sonar_data]]  # Target variable\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "def train_test_split(X, y, test_size=0.3, random_state=None):\n",
    "    if random_state:\n",
    "        random.seed(random_state)\n",
    "    \n",
    "    data = list(zip(X, y))\n",
    "    random.shuffle(data)\n",
    "    split_index = int(len(data) * (1 - test_size))\n",
    "    X_train, y_train = zip(*data[:split_index])\n",
    "    X_test, y_test = zip(*data[split_index:])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=5, max_features=20)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    correct = sum(1 for true, pred in zip(y_true, y_pred) if true == pred)\n",
    "    return correct / len(y_true)\n",
    "\n",
    "def precision_score(y_true, y_pred, pos_label):\n",
    "    true_positives = sum(1 for true, pred in zip(y_true, y_pred) if true == pos_label and pred == pos_label)\n",
    "    all_positives = sum(1 for pred in y_pred if pred == pos_label)\n",
    "    if all_positives == 0:\n",
    "        return 0\n",
    "    return true_positives / all_positives\n",
    "\n",
    "def recall_score(y_true, y_pred, pos_label):\n",
    "    true_positives = sum(1 for true, pred in zip(y_true, y_pred) if true == pos_label and pred == pos_label)\n",
    "    relevant = sum(1 for true in y_true if true == pos_label)\n",
    "    if relevant == 0:\n",
    "        return 0\n",
    "    return true_positives / relevant\n",
    "\n",
    "def f1_score(y_true, y_pred, pos_label):\n",
    "    precision = precision_score(y_true, y_pred, pos_label)\n",
    "    recall = recall_score(y_true, y_pred, pos_label)\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6525eaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
